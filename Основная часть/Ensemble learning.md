
## Что такое Ensemble Learning

С помощью EL можно объединить предсказания двух и более моделей для получения более надежной и производительной модели. Существует множество методологий для работы с ансамблями моделей. Здесь я затрону две самые полезные, чтобы дать общее представление.

С помощью **регрессии** можно усреднить показатели имеющихся моделей.

С помощью **классификации** можно давать возможность моделям выбирать лейблы. Лейбл, который выбирался чаще всего – тот, что будет выбран новой моделью.

## Почему EL работает лучше

Основная причина, по которой EL работает лучше, заключается в том, что у каждого предсказания есть ошибка (знаем мы это из теории вероятности), объединение двух предсказаний может помочь уменьшить ошибку, и, соответственно, улучшить показатели производительности (RMSE, R² и т.д.).

На следующей диаграмме видно, как два слабых алгоритма работают с набором данных. Первый алгоритм имеет больший угловой коэффициент, чем нужно, тогда как у второго он почти равен нулю (возможно, из-за чрезмерной регуляризации). Но _ensemble_ показывает результат куда лучше. 

Если смотреть на показатель R², то у первого и второго обучающего алгоритма он будет равен -0.01¹, 0.22, соответственно, тогда как у ансамбля он будет равен 0.73.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/6cb/5da/a38/6cb5daa38822df8db2233adcfa13a3fd.png)

Есть множество причин, по которым алгоритм может оказаться плохой моделью даже на таком базовом примере, как этот: может быть, вы решили использовать регуляризацию, чтобы избежать переобучения, или решили не исключать некоторые аномалии, а может использовали полиномиальную регрессию и подобрали неверную степень (например, использовали полином второй степени, а на тестовых данных видна явная асимметрия, для которой лучше подошла бы третья степень).

## Когда EL работает лучше

Давайте рассмотрим два обучающих алгоритма, работающих с одинаковыми данными.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/1e4/9ed/181/1e49ed1810471a877fb0cb01df20b959.png)

Здесь видно, что объединение двух моделей не сильно улучшило производительность. Изначально для двух обучающих алгоритмов показатели R² был равны -0,37 и 0,22, соответственно, а для ансамбля получилось -0,04. То есть модель EL получила среднее значение показателей.

Однако между этими двумя примерами есть большая разница: в первом примере ошибки моделей были отрицательно коррелированы, а во втором – положительно (коэффициенты трех моделей не оценивались, а просто были выбраны автором в качестве примера.)

Следовательно, Ensemble Learning может быть использовано для улучшения баланса смещения/дисперсии в любых случаях, но, когда _ошибки моделей не коррелированы положительно, использование EL может привести к повышению производительности_.

## Однородные и разнородные модели

Очень часто EL используется на однородных моделях (как в данном примере или в случайном лесу), но на самом деле вы можете комбинировать разные модели (линейную регрессию + нейронную сеть + XGBoost) с различными наборами объясняющих переменных. Скорее всего это приведет к некоррелированным ошибкам и повышению производительности.

## Сравнение с диверсификацией портфеля

_EL работает по аналогии с диверсификацией в теории портфеля, но тем лучше для нас._ 

При диверсификации вы пытаетесь уменьшить дисперсию ваших показателей, инвестируя в некоррелированные акции. Хорошо диверсифицированный портфель акций будет выдавать показатель лучше, чем наихудшая отдельная акция, но никогда не лучше, чем самая лучшая.

Цитируя Уоррена Баффета: 

> _«Диверсификация – это защита от невежества, для того, кто не знает, что он делает, она [диверсификация] имеет очень мало смысла.»_

В машинном обучении EL помогает уменьшить дисперсию вашей модели, но это может привести к созданию модели с общей производительностью лучше, чем лучшая изначальная модель.

## Что такое ансамбль?

Метод машинного обучения, где несколько моделей обучаются для решения одной и той же проблемы и объединяются для получения лучших результатов называется ансамблевым методом. Основная предпосылка заключается в том, что результат работы нескольких моделей будет более точен, чем результат только одной модели.

Когда говорится об ансамблях, то вводится понятие слабого ученика(обычные модели вроде линейной регрессии или дерева решений). Множество слабых учеников являются строительными блоками для более сложных моделей. Объединение слабых учеников для улучшения качества модели, уменьшения смещения или разброса, называется сильным учеником.

## Виды ансамблевых методов

Наиболее популярными ансамблевыми методами являются: стекинг, бэггинг, бустинг.

- **Стекинг**. Используется несколько разнородных слабых учеников. Их обучают и объединяют для построения прогноза, основанного на результатах различных слабых моделей.
    
- **Бэггинг**. В этом случае однородные модели обучают на разных наборах данных и объединяют. Получают прогноз путём усреднения. Если использовать в качестве слабого ученика деревья решений, то получится случайный лес [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) / [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html).
    
- **Бустинг**. При использовании данного метода несколько однородных моделей последовательно обучаются, исправляя ошибки друг друга.
    

## Стекинг

Работа этого типа ансамблей довольно проста. На вход всех слабых прогнозаторов подаётся обучающий набор, каждый прогноз идёт к финальной модели, которая называется смеситель, мета-ученик или мета-модель, после чего та вырабатывает финальный прогноз.

![Обучение мета-модели](https://habrastorage.org/r/w1560/getpro/habr/upload_files/139/8cd/1c9/1398cd1c90c6e69f7e50e3b1fc783c35.png "Обучение мета-модели")

Обучение мета-модели

При обучении мета-модели используется приём удерживаемого набора. Сначала набор разделяется на 2 части. Слабые ученики обучаются на первой половине обучающего набора, затем на второй. Затем создаётся новый обучающий набор на основе прогнозов, сделанных на прогнозах первой и второй части набора. Таким образом, на каждый образец из входного набора приходится столько прогнозов, сколько слабых учеников в ансамбле (в примере на картинке три). Мета-модель учится прогнозировать значения на основе нового набора.

## Бэггинг

Основная идея бэггинга заключается в том, чтобы обучить несколько одинаковых моделей на разных образцах. Распределение выборки неизвестно, поэтому модели получатся разными.

Для начала генерируется несколько бутстрэп-выборок. Бутстрэп - это случайный выбор данных из датасета и представление их в модель, затем данные возвращаются в датасет и процесс повторяется. После модели делают свои прогнозы на основе бутстрэп-выборок. В случае регрессии прогнозы просто усредняются. В случае же классификации применяется голосование.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/e69/3c2/2c7/e693c22c75565b0a4a0bc38220ab5a6b.png)

Если класс предсказывает большинство слабых моделей, то он получает больше голосов и данный класс является результатом предсказывания ансамбля. Это пример жёсткого голосования. При мягком голосовании рассматриваются вероятности предсказывания каждого класса, затем вероятности усредняются и результатом является класс с большой вероятностью.

## Бустинг

Метод бустинга в чём то схож с методом бэггинга: берётся множество одинаковых моделей и объединяется, чтобы получить сильного ученика. Но разница заключается в том, что модели приспосабливаются к данным последовательно, то есть каждая модель будет исправлять ошибки предыдущей.

Базовые модели для бустинга - это модели с низким разбросом и высоким смещением. Например неглубокие деревья решений. Одна из причин такого выбора моделей - они требуют меньше вычислительных затрат. Ещё бустинг (в отличии от бэггинга) нельзя распараллелить.

Существует два наиболее распространённых алгоритма бустинга - _адаптивный бустинг_ и _градиентный бустинг_. О них речь пойдёт ниже.

**Адаптивный бустинг (AdaBoost)**

Данный алгоритм сначала обучает первую базовую модель(допустим деревья решений) на тренировочном наборе. Относительный вес некорректно предсказанных значений увеличивается. На вход второй базовой модели подаются обновлённые веса и модель обучается, после чего вырабатываются прогнозы и цикл повторяется.

Результат работы AdaBoost - это средневзвешенная сумма каждой модели. Спрогнозированным значением ансамбля будет тот, который получает большинство взвешенный голосов

![C - результат работы ансамбля, W - вес, 
X - значение прогнозатора](https://habrastorage.org/r/w1560/getpro/habr/upload_files/15e/7a4/9d1/15e7a49d1d3aa6f73f26436d24a4285a.png "C - результат работы ансамбля, W - вес, 
X - значение прогнозатора")

C - результат работы ансамбля, W - вес, X - значение прогнозатора

Adaboost обновляет веса объектов на каждой итерации. Веса хорошо классифицированных объектов уменьшаются относительно весов неправильно классифицированных объектов. Модели, которые работают лучше, имеют больший вес в окончательной модели ансамбля.

При адаптивном бустинге используется _итеративный метод_ (добавляем слабых учеников одного за другим, просматривая каждую итерацию, чтобы найти наилучшую возможную пару (коэффициент, слабый ученик) для добавления к текущей модели ансамбля) изменения весов. Он работает быстрее, чем аналитический метод.